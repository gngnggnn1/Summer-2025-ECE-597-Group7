{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26cba2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from dataset.preprocessing import word_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f138b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model():\n",
    "    \"\"\"\n",
    "    Creates a Multi-layer Perceptron (MLP) model.\n",
    "    \"\"\"\n",
    "    # You can tune these parameters\n",
    "    model = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, alpha=1e-4,\n",
    "                        solver='adam', verbose=10, random_state=42,\n",
    "                        learning_rate_init=.001)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76291ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_mlp_with_kfold():\n",
    "    \"\"\"\n",
    "    Trains and evaluates an MLP model using k-fold cross-validation.\n",
    "    \"\"\"\n",
    "    print(\"Loading and vectorizing data...\")\n",
    "    tfidf_matrix, _, labels = word_vectorization('tfidf')\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = tfidf_matrix.toarray()\n",
    "    \n",
    "    # Encode labels\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(labels)\n",
    "    \n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    print(f\"Starting {n_splits}-fold cross-validation...\")\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        print(f\"--- Fold {fold+1}/{n_splits} ---\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = create_mlp_model()\n",
    "        \n",
    "        print(\"Training the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Evaluating the model...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold+1} Accuracy: {accuracy:.4f}\")\n",
    "        print(classification_report(y_test, y_pred, target_names=[str(c) for c in encoder.classes_]))\n",
    "\n",
    "    print(f\"\\nAverage cross-validation accuracy: {np.mean(accuracies):.4f} (+/- {np.std(accuracies):.4f})\")\n",
    "\n",
    "    # Train the final model on the entire dataset and save it\n",
    "    print(\"\\nTraining the final model on the entire dataset...\")\n",
    "    final_model = create_mlp_model()\n",
    "    final_model.fit(X, y)\n",
    "    print(\"Final model training complete.\")\n",
    "\n",
    "    model_filename = 'mlp_model.joblib'\n",
    "    joblib.dump(final_model, model_filename)\n",
    "    print(f\"\\nFinal model has been saved to '{model_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4fd8437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and vectorizing data...\n",
      "Starting 5-fold cross-validation...\n",
      "--- Fold 1/5 ---\n",
      "Training the model...\n",
      "Iteration 1, loss = 0.16424659\n",
      "Iteration 2, loss = 0.07531205\n",
      "Iteration 3, loss = 0.05559672\n",
      "Iteration 4, loss = 0.03947345\n",
      "Iteration 5, loss = 0.02676621\n",
      "Iteration 6, loss = 0.01785873\n",
      "Iteration 7, loss = 0.01139954\n",
      "Iteration 8, loss = 0.00766457\n",
      "Iteration 9, loss = 0.00548807\n",
      "Iteration 10, loss = 0.00415331\n",
      "Iteration 11, loss = 0.00391396\n",
      "Iteration 12, loss = 0.00333140\n",
      "Iteration 13, loss = 0.00336184\n",
      "Iteration 14, loss = 0.00318943\n",
      "Iteration 15, loss = 0.00324766\n",
      "Iteration 16, loss = 0.00314139\n",
      "Iteration 17, loss = 0.00365366\n",
      "Iteration 18, loss = 0.00338320\n",
      "Iteration 19, loss = 0.00269077\n",
      "Iteration 20, loss = 0.00265277\n",
      "Iteration 21, loss = 0.00231274\n",
      "Iteration 22, loss = 0.00236370\n",
      "Iteration 23, loss = 0.00243498\n",
      "Iteration 24, loss = 0.00228500\n",
      "Iteration 25, loss = 0.00225571\n",
      "Iteration 26, loss = 0.00223054\n",
      "Iteration 27, loss = 0.00226637\n",
      "Iteration 28, loss = 0.00228207\n",
      "Iteration 29, loss = 0.00217755\n",
      "Iteration 30, loss = 0.00224011\n",
      "Iteration 31, loss = 0.00540841\n",
      "Iteration 32, loss = 0.00608576\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Evaluating the model...\n",
      "Fold 1 Accuracy: 0.9815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7910\n",
      "           1       0.98      0.98      0.98      8588\n",
      "\n",
      "    accuracy                           0.98     16498\n",
      "   macro avg       0.98      0.98      0.98     16498\n",
      "weighted avg       0.98      0.98      0.98     16498\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Training the model...\n",
      "Iteration 1, loss = 0.16499457\n",
      "Iteration 2, loss = 0.07641881\n",
      "Iteration 3, loss = 0.05664516\n",
      "Iteration 4, loss = 0.04012877\n",
      "Iteration 5, loss = 0.02770950\n",
      "Iteration 6, loss = 0.01831100\n",
      "Iteration 7, loss = 0.01233953\n",
      "Iteration 8, loss = 0.00834839\n",
      "Iteration 9, loss = 0.00616408\n",
      "Iteration 10, loss = 0.00480926\n",
      "Iteration 11, loss = 0.00396207\n",
      "Iteration 12, loss = 0.00345512\n",
      "Iteration 13, loss = 0.00324418\n",
      "Iteration 14, loss = 0.00301321\n",
      "Iteration 15, loss = 0.00289590\n",
      "Iteration 16, loss = 0.00279023\n",
      "Iteration 17, loss = 0.00261994\n",
      "Iteration 18, loss = 0.00259657\n",
      "Iteration 19, loss = 0.00249789\n",
      "Iteration 20, loss = 0.00267836\n",
      "Iteration 21, loss = 0.01140185\n",
      "Iteration 22, loss = 0.00440097\n",
      "Iteration 23, loss = 0.00276428\n",
      "Iteration 24, loss = 0.00250280\n",
      "Iteration 25, loss = 0.00247107\n",
      "Iteration 26, loss = 0.00245821\n",
      "Iteration 27, loss = 0.00243596\n",
      "Iteration 28, loss = 0.00239421\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Evaluating the model...\n",
      "Fold 2 Accuracy: 0.9832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      7894\n",
      "           1       0.98      0.99      0.98      8603\n",
      "\n",
      "    accuracy                           0.98     16497\n",
      "   macro avg       0.98      0.98      0.98     16497\n",
      "weighted avg       0.98      0.98      0.98     16497\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Training the model...\n",
      "Iteration 1, loss = 0.16428569\n",
      "Iteration 2, loss = 0.07648746\n",
      "Iteration 3, loss = 0.05641610\n",
      "Iteration 4, loss = 0.03894560\n",
      "Iteration 5, loss = 0.02637496\n",
      "Iteration 6, loss = 0.01710546\n",
      "Iteration 7, loss = 0.01099494\n",
      "Iteration 8, loss = 0.00727034\n",
      "Iteration 9, loss = 0.00515360\n",
      "Iteration 10, loss = 0.00423146\n",
      "Iteration 11, loss = 0.00364707\n",
      "Iteration 12, loss = 0.00332003\n",
      "Iteration 13, loss = 0.00311247\n",
      "Iteration 14, loss = 0.00293948\n",
      "Iteration 15, loss = 0.00290952\n",
      "Iteration 16, loss = 0.00336693\n",
      "Iteration 17, loss = 0.00324728\n",
      "Iteration 18, loss = 0.00522910\n",
      "Iteration 19, loss = 0.00348641\n",
      "Iteration 20, loss = 0.00275530\n",
      "Iteration 21, loss = 0.00251748\n",
      "Iteration 22, loss = 0.00242098\n",
      "Iteration 23, loss = 0.00234347\n",
      "Iteration 24, loss = 0.00236366\n",
      "Iteration 25, loss = 0.00227892\n",
      "Iteration 26, loss = 0.00230157\n",
      "Iteration 27, loss = 0.00228275\n",
      "Iteration 28, loss = 0.00220964\n",
      "Iteration 29, loss = 0.00219237\n",
      "Iteration 30, loss = 0.00214209\n",
      "Iteration 31, loss = 0.00218172\n",
      "Iteration 32, loss = 0.00214457\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Evaluating the model...\n",
      "Fold 3 Accuracy: 0.9821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7916\n",
      "           1       0.98      0.99      0.98      8581\n",
      "\n",
      "    accuracy                           0.98     16497\n",
      "   macro avg       0.98      0.98      0.98     16497\n",
      "weighted avg       0.98      0.98      0.98     16497\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Training the model...\n",
      "Iteration 1, loss = 0.16456048\n",
      "Iteration 2, loss = 0.07745779\n",
      "Iteration 3, loss = 0.05878786\n",
      "Iteration 4, loss = 0.04152262\n",
      "Iteration 5, loss = 0.02920758\n",
      "Iteration 6, loss = 0.01951671\n",
      "Iteration 7, loss = 0.01294801\n",
      "Iteration 8, loss = 0.00853615\n",
      "Iteration 9, loss = 0.00597044\n",
      "Iteration 10, loss = 0.00474780\n",
      "Iteration 11, loss = 0.00385383\n",
      "Iteration 12, loss = 0.00352568\n",
      "Iteration 13, loss = 0.00318286\n",
      "Iteration 14, loss = 0.00292862\n",
      "Iteration 15, loss = 0.00274664\n",
      "Iteration 16, loss = 0.00258959\n",
      "Iteration 17, loss = 0.00255617\n",
      "Iteration 18, loss = 0.00244071\n",
      "Iteration 19, loss = 0.00240479\n",
      "Iteration 20, loss = 0.00547436\n",
      "Iteration 21, loss = 0.00737573\n",
      "Iteration 22, loss = 0.00266643\n",
      "Iteration 23, loss = 0.00234439\n",
      "Iteration 24, loss = 0.00232110\n",
      "Iteration 25, loss = 0.00231173\n",
      "Iteration 26, loss = 0.00220946\n",
      "Iteration 27, loss = 0.00223793\n",
      "Iteration 28, loss = 0.00223634\n",
      "Iteration 29, loss = 0.00228085\n",
      "Iteration 30, loss = 0.00217541\n",
      "Iteration 31, loss = 0.00214278\n",
      "Iteration 32, loss = 0.00219750\n",
      "Iteration 33, loss = 0.00225841\n",
      "Iteration 34, loss = 0.00221540\n",
      "Iteration 35, loss = 0.00221906\n",
      "Iteration 36, loss = 0.00322096\n",
      "Iteration 37, loss = 0.00526161\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Evaluating the model...\n",
      "Fold 4 Accuracy: 0.9805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7840\n",
      "           1       0.98      0.98      0.98      8657\n",
      "\n",
      "    accuracy                           0.98     16497\n",
      "   macro avg       0.98      0.98      0.98     16497\n",
      "weighted avg       0.98      0.98      0.98     16497\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Training the model...\n",
      "Iteration 1, loss = 0.16434929\n",
      "Iteration 2, loss = 0.07465162\n",
      "Iteration 3, loss = 0.05465155\n",
      "Iteration 4, loss = 0.03839162\n",
      "Iteration 5, loss = 0.02560323\n",
      "Iteration 6, loss = 0.01708393\n",
      "Iteration 7, loss = 0.01107177\n",
      "Iteration 8, loss = 0.00739746\n",
      "Iteration 9, loss = 0.00519884\n",
      "Iteration 10, loss = 0.00409215\n",
      "Iteration 11, loss = 0.00361534\n",
      "Iteration 12, loss = 0.00326669\n",
      "Iteration 13, loss = 0.00307906\n",
      "Iteration 14, loss = 0.00282322\n",
      "Iteration 15, loss = 0.00476295\n",
      "Iteration 16, loss = 0.00428675\n",
      "Iteration 17, loss = 0.00275481\n",
      "Iteration 18, loss = 0.00244993\n",
      "Iteration 19, loss = 0.00238535\n",
      "Iteration 20, loss = 0.00235189\n",
      "Iteration 21, loss = 0.00226008\n",
      "Iteration 22, loss = 0.00222374\n",
      "Iteration 23, loss = 0.00226446\n",
      "Iteration 24, loss = 0.00226028\n",
      "Iteration 25, loss = 0.00219083\n",
      "Iteration 26, loss = 0.00219769\n",
      "Iteration 27, loss = 0.00208208\n",
      "Iteration 28, loss = 0.00235817\n",
      "Iteration 29, loss = 0.00842246\n",
      "Iteration 30, loss = 0.00311085\n",
      "Iteration 31, loss = 0.00222149\n",
      "Iteration 32, loss = 0.00212124\n",
      "Iteration 33, loss = 0.00210441\n",
      "Iteration 34, loss = 0.00208768\n",
      "Iteration 35, loss = 0.00210163\n",
      "Iteration 36, loss = 0.00208770\n",
      "Iteration 37, loss = 0.00209436\n",
      "Iteration 38, loss = 0.00205749\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Evaluating the model...\n",
      "Fold 5 Accuracy: 0.9802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      8035\n",
      "           1       0.98      0.98      0.98      8462\n",
      "\n",
      "    accuracy                           0.98     16497\n",
      "   macro avg       0.98      0.98      0.98     16497\n",
      "weighted avg       0.98      0.98      0.98     16497\n",
      "\n",
      "\n",
      "Average cross-validation accuracy: 0.9815 (+/- 0.0011)\n",
      "\n",
      "Training the final model on the entire dataset...\n",
      "Iteration 1, loss = 0.14994597\n",
      "Iteration 2, loss = 0.07463723\n",
      "Iteration 3, loss = 0.05281024\n",
      "Iteration 4, loss = 0.03642884\n",
      "Iteration 5, loss = 0.02435725\n",
      "Iteration 6, loss = 0.01584993\n",
      "Iteration 7, loss = 0.01038463\n",
      "Iteration 8, loss = 0.00715573\n",
      "Iteration 9, loss = 0.00524616\n",
      "Iteration 10, loss = 0.00411820\n",
      "Iteration 11, loss = 0.00343383\n",
      "Iteration 12, loss = 0.00379293\n",
      "Iteration 13, loss = 0.00325578\n",
      "Iteration 14, loss = 0.00333584\n",
      "Iteration 15, loss = 0.00304696\n",
      "Iteration 16, loss = 0.00350922\n",
      "Iteration 17, loss = 0.00408804\n",
      "Iteration 18, loss = 0.00354985\n",
      "Iteration 19, loss = 0.00304215\n",
      "Iteration 20, loss = 0.00256697\n",
      "Iteration 21, loss = 0.00244642\n",
      "Iteration 22, loss = 0.00236173\n",
      "Iteration 23, loss = 0.00239068\n",
      "Iteration 24, loss = 0.00234653\n",
      "Iteration 25, loss = 0.00229431\n",
      "Iteration 26, loss = 0.00225805\n",
      "Iteration 27, loss = 0.00222057\n",
      "Iteration 28, loss = 0.00227228\n",
      "Iteration 29, loss = 0.00225996\n",
      "Iteration 30, loss = 0.00476173\n",
      "Iteration 31, loss = 0.00619419\n",
      "Iteration 32, loss = 0.00289091\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Final model training complete.\n",
      "\n",
      "Final model has been saved to 'mlp_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_mlp_with_kfold()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
