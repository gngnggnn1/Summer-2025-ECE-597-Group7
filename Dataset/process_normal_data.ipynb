{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc43ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "import warnings\n",
    "import email # This library is crucial for parsing raw email text files\n",
    "\n",
    "# Suppress future warnings from BeautifulSoup for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='bs4')\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98491ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined, including the Enron email parser.\n"
     ]
    }
   ],
   "source": [
    "def extract_features(data, text_column='body', subject_column='subject'):\n",
    "    \"\"\"This function is IDENTICAL to the one in Notebook 1 to ensure the feature columns match perfectly.\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # --- This critical line ensures NLTK finds its data ---\n",
    "    nltk.data.path.append(\"C:\\\\nltk_data_project\")\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    df['full_text'] = df[subject_column].fillna('') + ' ' + df[text_column].fillna('')\n",
    "    df['clean_text'] = df['full_text'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text(separator=' '))\n",
    "    df['clean_text'] = df['clean_text'].str.lower()\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    df['urls'] = df['full_text'].apply(lambda x: re.findall(url_pattern, str(x)))\n",
    "    df['num_hyperlinks'] = df['urls'].apply(len)\n",
    "    suspicious_domains = ['forms.gle', 'weebly.com', 'blogspot.com', 'glitch.me', 'repl.co', '.ipfs.', '127.0.0.1', 'bit.ly', 'tinyurl.com', 'dweb.link']\n",
    "    df['num_suspicious_links'] = df['urls'].apply(lambda urls: sum(1 for url in urls if any(domain in url for domain in suspicious_domains)))\n",
    "    df['num_ip_urls'] = df['urls'].apply(lambda urls: sum(1 for url in urls if re.search(r'/\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}/', url)))\n",
    "    df['body_char_count'] = df[text_column].str.len().fillna(0)\n",
    "    df['subject_char_count'] = df[subject_column].str.len().fillna(0)\n",
    "    urgency_words = ['urgent', 'action required', 'important notice', 'warning', 'verify', 'suspension', 'deactivation', 'unsuccessful', 'payment', 'invoice']\n",
    "    df['urgency_keyword_count'] = df['full_text'].str.lower().apply(lambda text: sum(1 for word in urgency_words if word in str(text)))\n",
    "    df['num_capital_words'] = df['clean_text'].apply(lambda text: len(re.findall(r'\\b[A-Z]{3,}\\b', str(text))))\n",
    "    df['special_char_ratio'] = df['full_text'].apply(lambda x: len(re.findall(r'[^a-zA-Z0-9\\s]', str(x))) / (len(str(x)) + 1e-6))\n",
    "    df['has_javascript'] = df[text_column].str.contains('<script>', case=False, na=False).astype(int)\n",
    "    df['has_form_tag'] = df[text_column].str.contains('<form>', case=False, na=False).astype(int)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    def preprocess_text_for_tfidf(text):\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text.lower()) # Use dependency-free regex tokenizer\n",
    "        lemmas = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "        return ' '.join(lemmas)\n",
    "    df['processed_text'] = df['clean_text'].apply(preprocess_text_for_tfidf)\n",
    "    feature_cols = ['num_hyperlinks', 'num_suspicious_links', 'num_ip_urls', 'body_char_count','subject_char_count', 'urgency_keyword_count', 'num_capital_words','special_char_ratio', 'has_javascript', 'has_form_tag', 'processed_text']\n",
    "    return df[feature_cols]\n",
    "\n",
    "def parse_enron_email(raw_email):\n",
    "    \"\"\"\n",
    "    Parses a raw email string (from the Enron dataset) into a subject and body.\n",
    "    \"\"\"\n",
    "    msg = email.message_from_string(raw_email)\n",
    "    subject = msg.get('Subject', '') # Use .get() for safety if Subject header is missing\n",
    "    body = \"\"\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            # We are only interested in the plain text part of the email\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                try:\n",
    "                    body = part.get_payload(decode=True).decode('utf-8', errors='replace')\n",
    "                except (UnicodeDecodeError, AttributeError):\n",
    "                    body = str(part.get_payload(decode=True)) # Fallback if decoding fails\n",
    "                break # Stop after finding the first plain text part\n",
    "    else:\n",
    "        # If the email is not multipart, the payload is the body\n",
    "        try:\n",
    "            body = msg.get_payload(decode=True).decode('utf-8', errors='replace')\n",
    "        except (UnicodeDecodeError, AttributeError):\n",
    "            body = str(msg.get_payload(decode=True))\n",
    "            \n",
    "    return subject, body\n",
    "\n",
    "print(\"Helper functions defined, including the Enron email parser.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e434c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing NORMAL (Enron) data from 'emails-normal-class.csv'...\n",
      "-> Loaded 517401 raw email messages.\n",
      "-> Parsing raw email messages into 'subject' and 'body' columns. This may take a moment...\n",
      "-> Engineering features for normal emails...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gngng\\AppData\\Local\\Temp\\ipykernel_19176\\3916070167.py:10: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a filename than HTML or XML.\n",
      "\n",
      "If you meant to use Beautiful Soup to parse the contents of a file on disk, then something has gone wrong. You should open the file first, using code like this:\n",
      "\n",
      "    filehandle = open(your filename)\n",
      "\n",
      "You can then feed the open filehandle into Beautiful Soup instead of using the filename.\n",
      "\n",
      "However, if you want to parse some data that happens to look like a filename, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import MarkupResemblesLocatorWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
      "    \n",
      "  df['clean_text'] = df['full_text'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text(separator=' '))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "SUCCESS! Processed 517401 normal emails.\n",
      "Saved the results to 'normal_features.csv'\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample of the saved data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_hyperlinks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_suspicious_links",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_ip_urls",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "body_char_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject_char_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "urgency_keyword_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_capital_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "special_char_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "has_javascript",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_form_tag",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "processed_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "de851ca2-fa42-4cf9-97dd-e219e02077c2",
       "rows": [
        [
         "0",
         "0",
         "0",
         "0",
         "23",
         "0",
         "0",
         "0",
         "0.0",
         "0",
         "0",
         "forecast",
         "0"
        ],
        [
         "1",
         "0",
         "0",
         "0",
         "786",
         "3",
         "0",
         "0",
         "0.01645569618170165",
         "0",
         "0",
         "traveling business meeting take fun trip especially prepare presentation would suggest holding business plan meeting take trip without formal business meeting would even try get honest opinion whether trip even desired necessary far business meeting think would productive try stimulate discussion across different group working often presenter speaks others quiet waiting turn meeting might better held round table discussion format suggestion go austin play golf rent ski boat jet ski flying somewhere take much time",
         "0"
        ],
        [
         "2",
         "0",
         "0",
         "0",
         "30",
         "8",
         "0",
         "0",
         "0.12820512491781733",
         "0",
         "0",
         "test test successful way go",
         "0"
        ],
        [
         "3",
         "0",
         "0",
         "0",
         "187",
         "0",
         "0",
         "0",
         "0.026595744539384337",
         "0",
         "0",
         "randy send schedule salary level everyone scheduling group plus thought change need made patti example phillip",
         "0"
        ],
        [
         "4",
         "0",
         "0",
         "0",
         "35",
         "9",
         "0",
         "0",
         "0.0888888869135803",
         "0",
         "0",
         "hello let shoot tuesday",
         "0"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_hyperlinks</th>\n",
       "      <th>num_suspicious_links</th>\n",
       "      <th>num_ip_urls</th>\n",
       "      <th>body_char_count</th>\n",
       "      <th>subject_char_count</th>\n",
       "      <th>urgency_keyword_count</th>\n",
       "      <th>num_capital_words</th>\n",
       "      <th>special_char_ratio</th>\n",
       "      <th>has_javascript</th>\n",
       "      <th>has_form_tag</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forecast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>traveling business meeting take fun trip espec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test test successful way go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>randy send schedule salary level everyone sche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hello let shoot tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_hyperlinks  num_suspicious_links  num_ip_urls  body_char_count  \\\n",
       "0               0                     0            0               23   \n",
       "1               0                     0            0              786   \n",
       "2               0                     0            0               30   \n",
       "3               0                     0            0              187   \n",
       "4               0                     0            0               35   \n",
       "\n",
       "   subject_char_count  urgency_keyword_count  num_capital_words  \\\n",
       "0                   0                      0                  0   \n",
       "1                   3                      0                  0   \n",
       "2                   8                      0                  0   \n",
       "3                   0                      0                  0   \n",
       "4                   9                      0                  0   \n",
       "\n",
       "   special_char_ratio  has_javascript  has_form_tag  \\\n",
       "0            0.000000               0             0   \n",
       "1            0.016456               0             0   \n",
       "2            0.128205               0             0   \n",
       "3            0.026596               0             0   \n",
       "4            0.088889               0             0   \n",
       "\n",
       "                                      processed_text  label  \n",
       "0                                           forecast      0  \n",
       "1  traveling business meeting take fun trip espec...      0  \n",
       "2                        test test successful way go      0  \n",
       "3  randy send schedule salary level everyone sche...      0  \n",
       "4                            hello let shoot tuesday      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_filepath = 'emails-normal-class.csv'\n",
    "print(f\"Loading and processing NORMAL (Enron) data from '{normal_filepath}'...\")\n",
    "\n",
    "try:\n",
    "    # This file has a 'file' and 'message' column. We will process the 'message' column.\n",
    "    normal_df_raw = pd.read_csv(normal_filepath, encoding='utf-8')\n",
    "    print(f\"-> Loaded {len(normal_df_raw)} raw email messages.\")\n",
    "    \n",
    "    # Use our special parser to extract 'subject' and 'body' from the 'message' column\n",
    "    print(\"-> Parsing raw email messages into 'subject' and 'body' columns. This may take a moment...\")\n",
    "    parsed_emails = normal_df_raw['message'].apply(lambda x: pd.Series(parse_enron_email(x), index=['subject', 'body']))\n",
    "    \n",
    "    # Now that we have a standard DataFrame, apply our feature engineering function\n",
    "    print(\"-> Engineering features for normal emails...\")\n",
    "    normal_features = extract_features(parsed_emails)\n",
    "    \n",
    "    # Add the label for this dataset (0 for normal)\n",
    "    normal_features['label'] = 0\n",
    "    \n",
    "    # Define the output filename for our second checkpoint\n",
    "    output_filename = 'normal_features.csv'\n",
    "    \n",
    "    # Save the processed data to a new CSV file\n",
    "    normal_features.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"SUCCESS! Processed {len(normal_features)} normal emails.\")\n",
    "    print(f\"Saved the results to '{output_filename}'\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Display the first few rows of the output for verification\n",
    "    print(\"\\nSample of the saved data:\")\n",
    "    display(normal_features.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: The file '{normal_filepath}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
