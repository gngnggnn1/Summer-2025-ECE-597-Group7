{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd33027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Set a nice plotting style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff021a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed data...\n",
      "FATAL ERROR: Could not find the required file: phishing_features.csv\n",
      "Please make sure 'phishing_features.csv' and 'normal_features.csv' are in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Loading pre-processed data...\")\n",
    "    phishing_df = pd.read_csv('phishing_features.csv')\n",
    "    normal_df = pd.read_csv('normal_features.csv')\n",
    "    print(f\"-> Loaded {len(phishing_df)} phishing records and {len(normal_df)} normal records.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: Could not find the required file: {e.filename}\")\n",
    "    print(\"Please make sure 'phishing_features.csv' and 'normal_features.csv' are in the same folder as this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc13f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 80/20 split and combining data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'phishing_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating 80/20 split and combining data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m n_phishing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mphishing_df\u001b[49m)\n\u001b[0;32m      3\u001b[0m n_normal_needed \u001b[38;5;241m=\u001b[39m n_phishing \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# 80% is 4 times 20%\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(normal_df) \u001b[38;5;241m<\u001b[39m n_normal_needed:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'phishing_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Calculating 80/20 split and combining data...\")\n",
    "n_phishing = len(phishing_df)\n",
    "n_normal_needed = n_phishing * 4  # 80% is 4 times 20%\n",
    "\n",
    "if len(normal_df) < n_normal_needed:\n",
    "    print(f\"WARNING: You have {len(normal_df)} normal emails, but {n_normal_needed} are needed for a perfect 80/20 split.\")\n",
    "    print(\"-> Using all available normal emails.\")\n",
    "    normal_sampled = normal_df\n",
    "else:\n",
    "    print(f\"-> Sampling {n_normal_needed} normal emails from the available {len(normal_df)}.\")\n",
    "    normal_sampled = normal_df.sample(n=n_normal_needed, random_state=42)\n",
    "\n",
    "# Combine the phishing data with the sampled normal data\n",
    "final_df = pd.concat([phishing_df, normal_sampled], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset to mix the phishing and normal emails randomly\n",
    "final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "phish_percent = (final_df['label'].sum() / len(final_df)) * 100\n",
    "print(\"-\" * 50)\n",
    "print(\"Dataset Assembled and Shuffled!\")\n",
    "print(f\"Total emails in final dataset: {len(final_df)}\")\n",
    "print(f\"Final composition: {len(phishing_df)} phishing, {len(normal_sampled)} normal.\")\n",
    "print(f\"Phishing emails make up {phish_percent:.2f}% of the final dataset.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "display(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04c81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating visualizations...\")\n",
    "\n",
    "# 1. Word Cloud\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Word cloud for phishing emails\n",
    "plt.subplot(1, 2, 1)\n",
    "# Ensure all text is a string to prevent errors\n",
    "phishing_text = ' '.join(final_df[final_df['label'] == 1]['processed_text'].astype(str))\n",
    "wordcloud_phish = WordCloud(width=800, height=400, background_color='black', colormap='Reds').generate(phishing_text)\n",
    "plt.imshow(wordcloud_phish, interpolation='bilinear')\n",
    "plt.title('Most Common Words in Phishing Emails', fontsize=15)\n",
    "plt.axis('off')\n",
    "\n",
    "# Word cloud for normal emails\n",
    "plt.subplot(1, 2, 2)\n",
    "# Ensure all text is a string\n",
    "normal_text = ' '.join(final_df[final_df['label'] == 0]['processed_text'].astype(str))\n",
    "wordcloud_normal = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(normal_text)\n",
    "plt.imshow(wordcloud_normal, interpolation='bilinear')\n",
    "plt.title('Most Common Words in Normal Emails', fontsize=15)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. Feature Distribution Plots\n",
    "feature_cols_to_plot = [\n",
    "    'num_hyperlinks', 'num_suspicious_links', 'urgency_keyword_count', \n",
    "    'body_char_count', 'special_char_ratio', 'num_capital_words'\n",
    "]\n",
    "\n",
    "print(\"\\nComparing feature distributions...\")\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, col in enumerate(feature_cols_to_plot, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    # Using a log scale is good for skewed data like counts\n",
    "    sns.histplot(data=final_df, x=col, hue='label', bins=30, log_scale=True, palette={0: 'blue', 1: 'red'})\n",
    "    plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'ready_for_training.csv'\n",
    "final_df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"FINAL STEP COMPLETE!\")\n",
    "print(f\"The final, feature-engineered, and balanced dataset has been saved as '{output_filename}'.\")\n",
    "print(\"\\nYou are now ready to begin the Machine Learning Training and Implementation phase.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
